{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95220aeb-e7d6-43ba-9f8f-a83b7f62ccb2",
   "metadata": {},
   "source": [
    "# ABC Guide for XMM-Newton -- Chapter 10 (RGS Data Processing)\n",
    "\n",
    "---\n",
    "\n",
    "#### Introduction\n",
    "This tutorial is based on Chapter 10 from the [The XMM-Newton ABC Guide](https://heasarc.gsfc.nasa.gov/docs/xmm/abc/ \"ABC Guide\") prepared by the NASA/GSFC XMM-Newton Guest Observer Facility. This notebook assumes you are using the version of pySAS found on [GitHub](https://github.com/XMMGOF/pysas) and have already configured it to work with your SAS installation (see the [README on GitHub](https://github.com/XMMGOF/pysas/blob/main/README.md)). \n",
    "#### Expected Outcome\n",
    "The ability to process RGS data and prepare it for analysis.\n",
    "#### SAS Tasks to be Used\n",
    "\n",
    "- `rgsproc`[(Documentation for epproc)](https://xmm-tools.cosmos.esa.int/external/sas/current/doc/rgsproc/index.html \"rgsproc Documentation\")\n",
    "- `evselect`[(Documentation for evselect)](https://xmm-tools.cosmos.esa.int/external/sas/current/doc/evselect/index.html)\n",
    "- `tabgtigen`[(Documentation for tabgtigen)](https://xmm-tools.cosmos.esa.int/external/sas/current/doc/tabgtigen/index.html)\n",
    "- `gtibuild`[(Documentation for gtibuild)](https://xmm-tools.cosmos.esa.int/external/sas/current/doc/gtibuild/index.html)\n",
    "\n",
    "#### Prerequisites\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Before running this notebook, or even starting a Jupyter Lab session, HEASOFT has to be initialized. If you did not initalize HEASOFT before starting this Jupyter Lab session, or opening this notebook, please close this window and initalize HEASOFT (it is not possible to initalize HEASOFT from within a Jupyter Notebook). SAS defaults for your machine will need to be set as explained in the README on GitHub (https://github.com/XMMGOF/pysas/blob/main/README.md).\n",
    "</div>\n",
    "\n",
    "#### Useful Links\n",
    "\n",
    "- [`pysas` Documentation](https://xmm-tools.cosmos.esa.int/external/sas/current/doc/pysas/index.html \"pysas Documentation\")\n",
    "- [`pysas` on GitHub](https://github.com/XMMGOF/pysas)\n",
    "- [Common SAS Threads](https://www.cosmos.esa.int/web/xmm-newton/sas-threads \"SAS Threads\")\n",
    "- [Users' Guide to the XMM-Newton Science Analysis System (SAS)](https://xmm-tools.cosmos.esa.int/external/xmm_user_support/documentation/sas_usg/USG/SASUSG.html \"Users' Guide\")\n",
    "- [The XMM-Newton ABC Guide](https://heasarc.gsfc.nasa.gov/docs/xmm/abc/ \"ABC Guide\")\n",
    "- [XMM Newton GOF Helpdesk](https://heasarc.gsfc.nasa.gov/docs/xmm/xmm_helpdesk.html \"Helpdesk\") - Link to form to contact the GOF Helpdesk.\n",
    "\n",
    "#### Caveats\n",
    "This tutorial uses an observation of Mkn 421 (obsid = '0153950701')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eebc609-8d0a-40be-a848-cc6abf26f406",
   "metadata": {},
   "source": [
    "##### Last Reviewed: _25 June 2024, for SAS v21_\n",
    "##### Last Updated: _25 June 2024_\n",
    "##### By: Ryan Tanner (ryan.tanner@nasa.gov)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c8366-38cb-4a4f-ad8c-75937fe0484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pySAS imports\n",
    "import pysas\n",
    "from pysas.wrapper import Wrapper as w\n",
    "\n",
    "# Useful imports\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import astropy_mpl_style\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.table import Table\n",
    "plt.style.use(astropy_mpl_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b6683-eb97-4ed6-8530-41712367eebb",
   "metadata": {},
   "source": [
    "### 10.1 : Rerun basic processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fd5c57-eb12-4fe7-8387-e25d73988b70",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> Running rgsproc on this particular obsid will take A LONG TIME, depending on your machine. Be prepared to wait.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b52b56f-e3a3-4109-ab96-426130531578",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "obsid = '0153950701'\n",
    "odf = pysas.odfcontrol.ODFobject(obsid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e45876-d6cb-4f7a-9975-6f1dbeb42e15",
   "metadata": {},
   "source": [
    "We start by reprocessing the data. Since we are only interested in the RGS data we do not have to run `epproc` and `emproc`. By default `basic_setup` will run `epproc`,`emproc`, and `rgsproc`, so we will set `run_epproc` and `run_emproc` to `False`.\n",
    "\n",
    "We will also use the rgsproc inputs, `orders='1 2' bkgcorrect=no withmlambdacolumn=yes spectrumbinning=lambda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d3e8c-7b88-4aee-b20b-9fb2ba784f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgsproc_args = [\"orders='1 2'\",\n",
    "                'bkgcorrect=no',\n",
    "                'withmlambdacolumn=yes',\n",
    "                'spectrumbinning=lambda']\n",
    "odf.basic_setup(overwrite=False,repo='heasarc',rerun=True,run_epproc=False,run_emproc=False,rgsproc_args=rgsproc_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982411c-5d03-48d4-adb5-9e88800a9330",
   "metadata": {},
   "source": [
    "The input arguments for `rgsproc` are:\n",
    "\n",
    "    orders - dispersion orders to extract\n",
    "    bkgcorrect - subtract background from source spectra?\n",
    "    withmlambdacolumn - include a wavelength column in the event file product\n",
    "    spectrumbinning - accumulate the spectrum either in wavelength or beta space\n",
    "\n",
    "Note the last keyword, `spectrumbinning`. If you want to merge data from the same orders in RGS1 and RGS2, keep it at the default value `lambda`. If you want to merge data from the same instrument, with different orders, set it to `beta`. Merging spectra is discussed in ยง10.6.\n",
    "\n",
    "This takes several minutes, and outputs 12 files per RGS, plus 3 general use FITS files. As before, links to the event list files are stored in `odf.files['R1evt_list']` and `odf.files['R2evt_list']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab90f82-c8e8-4ba4-9ee4-fe98d9c597fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(odf.files['R1evt_list'])\n",
    "print(odf.files['R2evt_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13dfdc-66e2-43a8-8ffc-cf38f2b4cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "odf.get_event_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40464a2-5fe1-412d-9461-23b5eb35c98d",
   "metadata": {},
   "source": [
    "### 10.1.1 : Potentially useful tips for using the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055a0fc-14d0-4632-84a9-7fc5ebba0188",
   "metadata": {},
   "source": [
    "The pipeline task, rgsproc, is very flexible and can address potential pitfalls for RGS users. In ยง10.1, we used a simple set of parameters with the task; if this is sufficient for your data (and it should be for most), feel free to skip to later sections, where data filters are discussed. In the following subsections, we will look at the cases of a nearby bright optical source, a nearby bright X-ray source, and a user-defined source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534d65a-d977-4e61-b380-f9e696db45e5",
   "metadata": {},
   "source": [
    "### 10.1.2 : A Nearby Bright Optical Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da2caf-cec0-423a-aef6-d991c0a17f72",
   "metadata": {},
   "source": [
    "With certain pointing angles, zeroth-order optical light may be reflected off the telescope optics and cast onto the RGS CCD detectors. If this falls on an extraction region, the current energy calibration will require a wavelength-dependent zero-offset. Stray light can be detected on RGS DIAGNOSTIC images taken before, during and after the observation. This test, and the offset correction, are not performed on the data before delivery. Please note that this will not work in every case. If a source is very bright, the diagnostic data that this relies on may not have been downloaded from the telescope in order to save bandwidth. Also, the RGS target itself cannot be the source of optical photons, as the spectrum's zero-order falls far from the RGS chip array. To check for stray light and apply the appropriate offsets, use the following inputs.\n",
    "\n",
    "```python\n",
    "rgsproc_args = [\"orders='1 2'\",\n",
    "                'bkgcorrect=no',\n",
    "                'calcoffsets=yes',\n",
    "                'withoffsethistogram=no']\n",
    "```\n",
    "\n",
    "where the parameters are as described in ยง10.1 and\r\n",
    "    \r\n",
    "calcoffsets - calculate PHA offsets from diagnostic image    s\r\n",
    "withoffsethistogram - produce a histogram of uncalibrated excess for the user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd206554-c25d-423d-84ee-2fce2816d944",
   "metadata": {},
   "source": [
    "### 10.1.3 : A Nearby Bright X-ray Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b968e-9b0d-4b88-9ef3-2dbd53fc9f24",
   "metadata": {},
   "source": [
    "In the example above, it is assumed that the field around the source contains sky only. Provided a bright background source is well-separated from the target in the cross-dispersion direction, a mask can be created that excludes it from the background region. Here the source has been identified in the EPIC images and its coordinates have been taken from the EPIC source list which is included among the pipeline products. The bright neighboring object is found to be the third source listed in the sources file. The first source is the target. The inputs would be\n",
    "\n",
    "```python\n",
    "rgsproc_args = [\"orders='1 2'\",\n",
    "                'bkgcorrect=no',\n",
    "                'withepicset=yes',\n",
    "                'epicset=P0153950701EPX000OMSRLI0000.FTZ',\n",
    "                \"exclsrcsexpr='INDEX==1&&INDEX==3'\"]\n",
    "```\n",
    "\n",
    "where the parameters are as described in ยง10.1 and\n",
    "\n",
    "    withepicset - calculate extraction regions for the sources contained in an EPIC source list\n",
    "    epicset - name of the EPIC source list, such as generated by emldetect or eboxdetect procedures\n",
    "    exclsrcsexpr - expression to identify which source(s) should be excluded from the background extraction region\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Notice:</b> This method uses an <b>OMSRLI</b> file which is found in the pipeline products (PPS). <b>OMSRLI</b> stands for Observation Maximum-Likelihood Source List, in this case OM does <i>not</i> stand for 'Optical Monitor'. You will need to download the PPS files for this. This can be done by using the command <b>odf.calibrate_odf(overwrite=False,level='PPS')</b>. The file will be in the '$data_dir/obsid/PPS/' directory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d02eba3-5bcc-4dfa-83f4-ab2c5ec9b68e",
   "metadata": {},
   "source": [
    "### 10.1.4 : User-defined Source Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0e26f-8ead-4a7d-bbb1-c737f8a9519a",
   "metadata": {},
   "source": [
    "If the true coordinates of an object are not included in the EPIC source list or the science proposal, the user can define the coordinates of a new source by typing:\n",
    "\n",
    "```python\n",
    "rgsproc_args = [\"orders='1 2'\",\n",
    "                'bkgcorrect=no',\n",
    "                'withsrc=yes',\n",
    "                'srclabel=Mkn421',\n",
    "                'srcstyle=radec',\n",
    "                'srcra=166.113808',\n",
    "                'srcdec=+38.208833']\n",
    "```\n",
    "\n",
    "where the parameters are as described in ยง10.1 and\n",
    "\n",
    "    withsrc - make the source be user-defined\n",
    "    srclabel - source name\n",
    "    srcstyle - coordinate system in which the source position is defined\n",
    "    srcra - the source's right ascension in decimal degrees\n",
    "    srcdec - the source's declination in decimal degrees\n",
    "    \n",
    "Since the event files are current, we can proceed with some simple analysis demonstrations, which will allow us to generate filters. Rememer that all tasks should be called from the work directory, and that tasks place output files in whatever directory you are in when they are called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8c1fe-3fc9-48af-97c6-7e7cbdea4ab5",
   "metadata": {},
   "source": [
    "### 10.2 : Create and Display an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141d2fc3-247b-4f59-872b-406462f45cfb",
   "metadata": {},
   "source": [
    "Two commonly-made plots are those showing PI vs. BETA_CORR (also known as 'banana plots') and XDSP_CORR vs. BETA_CORR.\n",
    "\n",
    "The input arguments to `evselect` to create these FITS image files are:\n",
    "\n",
    "    table - input event table\n",
    "    withimageset - make an image\n",
    "    imageset - name of output image\n",
    "    xcolumn - event column for X axis\n",
    "    ycolumn - event column for Y axis\n",
    "    imagebinning - form of binning, force entire image into a given size or bin by a specified number of pixels\n",
    "    ximagesize - output image pixels in X\n",
    "    yimagesize - output image pixels in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b9cfc-8467-479c-b8c6-61bec06f6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fits_image(event_list_file, image_file='image.fits', xcolumn='BETA_CORR', ycolumn='PI', expression=None):\n",
    "    \n",
    "    inargs = {}\n",
    "    inargs['table']        = event_list_file+':EVENTS'\n",
    "    inargs['withimageset'] = 'yes'\n",
    "    inargs['imageset']     = image_file\n",
    "    inargs['xcolumn']      = xcolumn\n",
    "    inargs['ycolumn']      = ycolumn\n",
    "    inargs['imagebinning'] = 'imageSize'\n",
    "    inargs['ximagesize']   = '600'\n",
    "    inargs['yimagesize']   = '600'\n",
    "    if expression != None:\n",
    "        inargs['expression'] = expression\n",
    "    \n",
    "    w('evselect', inargs).run()\n",
    "\n",
    "    hdu = fits.open(image_file)[0]\n",
    "    plt.imshow(hdu.data, origin='lower', norm='log')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca8592-a53f-4d9f-b7de-dfdcd48477e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(odf.work_dir)\n",
    "R1_event_list = odf.files['R1evt_list'][0]\n",
    "make_fits_image(R1_event_list,image_file='pi_bc.fits')\n",
    "make_fits_image(R1_event_list,image_file='xd_bc.fits', xcolumn='BETA_CORR', ycolumn='XDSP_CORR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dc7f19-3238-4bf8-bda1-0809de59316e",
   "metadata": {},
   "source": [
    "### 10.3 : Create and Display a Light Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60858424-69ba-4a71-a6c2-b63fdd610958",
   "metadata": {},
   "source": [
    "The background is assessed through examination of the light curve. We will extract a region, CCD9, that is most susceptible to proton events and generally records the least source events due to its location close to the optical axis. Also, to avoid confusing solar flares for source variability, a region filter that removes the source from the final event list should be used. The region filters are kept in the source file product `*SRCLI_*.FIT`. `rgsproc` outputs an `M_LAMBDA` column which can be used to generate the light curve. (The `*SRCLI_*.FIT` file that came with the PPS products contains a `BETA_CORR` column if you prefer to use that instead.)\n",
    "\n",
    "The input arguments to `evselect` to create a light curve file are:\n",
    "\n",
    "    table - input event table\n",
    "    withrateset - make a light curve\n",
    "    rateset - name of output light curve file\n",
    "    maketimecolumn - control to create a time column\n",
    "    timecolumn - time column label\n",
    "    timebinsize - time binning (seconds)\n",
    "    makeratecolumn - control to create a count rate column, otherwise a count column will be created\n",
    "    expression - filtering expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f98330-8c09-4c13-acf1-f59d95d9fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_light_curve(event_list_file, light_curve_file='ltcrv.fits',expression=None):\n",
    "                     \n",
    "    inargs = {'table': event_list_file, \n",
    "              'withrateset': 'yes', \n",
    "              'rateset': light_curve_file, \n",
    "              'maketimecolumn': 'yes', \n",
    "              'timecolumn': 'TIME', \n",
    "              'timebinsize': '50', \n",
    "              'makeratecolumn': 'yes'}\n",
    "\n",
    "    if expression != None:\n",
    "        inargs['expression'] = expression\n",
    "\n",
    "    w('evselect', inargs).run()\n",
    "\n",
    "    ts = Table.read(light_curve_file,hdu=1)\n",
    "    plt.plot(ts['TIME'],ts['RATE'])\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Count Rate (ct/s)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87960082-58b6-44e2-96ea-5faefb7f97bc",
   "metadata": {},
   "source": [
    "Sometimes, it is necessary to use filters on time in addition to those mentioned above. This is because of soft proton background flaring, which can have count rates of 100 counts/sec or higher across the entire bandpass.\n",
    "\n",
    "To determine if our observation is affected by background flaring, we can examine the light curve. For the time binning, we will set it to something reasonable (usually between 10 and 100 s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b04b0-0aef-43aa-83a6-5ada7da81221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expression = '(CCDNR==9)&&(REGION(P0153950701R1S001SRCLI_0000.FIT:RGS1_BACKGROUND,M_LAMBDA,XDSP_CORR))'\n",
    "plot_light_curve(R1_event_list, light_curve_file='r1_ltcrv.fits', expression=expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079d2b3-3796-459d-9269-e6fc32117dde",
   "metadata": {},
   "source": [
    "In this case no flares are evident, so we will continue to the next section. However, if a dataset does contain flares, they should be removed in the same way as shown for EPIC Imaging mode data in ยง6.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eb2765-3e0e-4a7e-b96e-e9d8f7c60fed",
   "metadata": {},
   "source": [
    "### 8.5 : Extract the Source and Background Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf67643-fd5d-4cfa-acd3-a91d7081c92f",
   "metadata": {},
   "source": [
    "The first step in extracting a spectrum from PN Timing data is to make an image of the event file over the energy range we are interested in; for this example, we'll say 0.5-15 keV. And since this is the PN, we need to remember to set `(FLAG==0)` to get a high-quality spectrum. Thus, our expression parameter would be set to `(FLAG==0) && (PI in [500:15000])`, and we make a new image using this expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd28abd-b95e-4542-823d-03d8b76dd82b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_fits_image(basic_filter_file, image_file=final_filter_image, \n",
    "                expression=\"'(FLAG==0) && (PI in [500:15000])'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67824c-4e50-4daf-ae3c-58e36beb78b8",
   "metadata": {},
   "source": [
    "The source is centered on `RAWX=37`; we will extract this and the 10 pixels on either side of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24455ebb-c164-4bc8-9099-4b0bc44e35c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = \"'(FLAG==0) && (PI in [500:15000]) && (RAWX in [27:47])'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190c834-4359-4903-b4f7-c8b0f26ddf4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inargs = {}\n",
    "inargs['table']           = basic_filter_file\n",
    "inargs['spectrumset']     = source_pi_file\n",
    "inargs['energycolumn']    = 'PI'\n",
    "inargs['spectralbinsize'] = '5'\n",
    "inargs['specchannelmin']  = '0'\n",
    "inargs['specchannelmax']  = '20479'\n",
    "inargs['withfilteredset'] = 'yes'\n",
    "inargs['filteredset']     = pn_spectra_file\n",
    "inargs['expression']      = expression\n",
    "\n",
    "w('evselect', inargs).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6c44b-80e9-48a2-90d3-4cb1e9e19e1e",
   "metadata": {},
   "source": [
    "For the background, the extraction area should be as far from the source as possible. However, sources with > 200 ct/s (like our example!) are so bright that they dominate the entire CCD area, and there is no source-free region from which to extract a background. (It goes without saying that this is highly energy-dependent.) In such a case, it may be best not to subtract a background. Users are referred to Ng et al. (2010, A&A, 522, 96) for an in-depth discussion. While this observation is too bright to have a good background extraction region, the process is shown below nonetheless for the sake of demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a174a-a33b-4e82-a62b-5a3c06927251",
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = \"'(FLAG==0) && (PI in [500:15000]) && (RAWX in [3:5])'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608401c-3b97-4f24-8b50-79884f565a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inargs = {}\n",
    "inargs['table']           = basic_filter_file\n",
    "inargs['withspectrumset'] = 'yes'\n",
    "inargs['spectrumset']     = bkg_pi_file\n",
    "inargs['energycolumn']    = 'PI'\n",
    "inargs['spectralbinsize'] = '5'\n",
    "inargs['withspecranges']  = 'yes'\n",
    "inargs['specchannelmin']  = '0'\n",
    "inargs['specchannelmax']  = '20479'\n",
    "inargs['withfilteredset'] = 'yes'\n",
    "inargs['filteredset']     = pn_bkg_file\n",
    "inargs['expression']      = expression\n",
    "\n",
    "w('evselect', inargs).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73807e-bba2-4001-8eec-7b74f34bc57d",
   "metadata": {},
   "source": [
    "### 8.6 : Check for Pile Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2dea8-c360-4d40-b3b9-92906247861d",
   "metadata": {},
   "source": [
    "Depending on how bright the source is and what modes the EPIC detectors are in, event pile up may be a problem. Pile up occurs when a source is so bright that incoming X-rays strike two neighboring pixels or the same pixel in the CCD more than once in a read-out cycle. In such cases the energies of the two events are in effect added together to form one event. If this happens sufficiently often, \n",
    "\n",
    "    1. The spectrum will appear to be harder than it actually is, and \n",
    "    2. The count rate will be underestimated, since multiple events will be undercounted. \n",
    "\n",
    "Briefly, we deal with it in PN Timing data essentially the same way as in Imaging data, that is, by using only single pixel events, and/or removing the regions with very high count rates, checking the amount of pile up, and repeating until it is no longer a problem. We recommend to always check for it.\n",
    "\n",
    "Note that this procedure requires as input the event files created when the spectrum was made (i.e. `pn_spectra_file = 'pn_filt_source_WithBore.fits'`), not the usual time-filtered event file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd74ccc-fc80-4a6f-b4b7-6518291bab1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inargs = ['set={0}'.format(pn_spectra_file),\n",
    "          'plotfile=pn_epat.ps',\n",
    "          'useplotfile=yes',\n",
    "          'withbackgroundset=yes',\n",
    "          'backgroundset={0}'.format(pn_bkg_file)]\n",
    "\n",
    "w('epatplot', inargs).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc46ae-c0f8-4118-a86a-e0c84bc79d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_out = subprocess.run(['gv','pn_epat.ps'],stdout = subprocess.DEVNULL)\n",
    "# Note: You will need to close the window that opens to run the remaining cells in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a166218-9095-4ca2-9da7-dffeabee9b66",
   "metadata": {},
   "source": [
    "The output of epatplot is a postscript file, `pn_epat.ps`, which may be viewed with viewers such as `gv`, containing two graphs describing the distribution of counts as a function of PI channel; see figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3080244a-1852-4e5b-b3f9-9d3c90273043",
   "metadata": {},
   "source": [
    "<center><img src=\"__images/pile_up_Cen_X-3.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a49676-6a55-48dc-9776-7738a5bd1b88",
   "metadata": {},
   "source": [
    "A few words about interpretting the plots are in order. The top is the distribution of counts versus PI channel for each pattern class (single, double, triple, quadruple), and the bottom is the expected pattern distribution (smooth lines) plotted over the observed distribution (line with noise). The lower plot shows the model distributions for single and double events and the observed distributions. It also gives the ratio of observed-to-modeled events with $1-\\sigma$ uncertainties for single and double pattern events over a given energy range. (The default is 0.5-2.0 keV; this can be changed with the `pileupnumberenergyrange` parameter.) If the data is not piled up, there will be good agreement between the modeled and observed single and double event pattern distributions. Also, the observed-to-modeled fractions for both singles and doubles in the 0.5-2.0 keV range will be unity, within errors. In contrast, if the data is piled up, there will be clear divergence between the modeled and observed pattern distributions, and the observed-to-modeled fraction for singles will be less than 1.0, and for doubles, it will be greater than 1.0.\n",
    "\n",
    "Finally, when examining the plots, it should noted that the observed-to-modeled fractions can be inaccurate. Therefore, the agreement between the modeled and observed single and double event pattern distributions should be the main factor in determining if an observation is affected by pile up or not.\n",
    "\n",
    "Examining the plots, we see that there is a large difference between the modeled and observed single and double pattern events at $> 1.0$ keV, but this divergence is not reflected in the observed-to-model fractions since for singles it is $> 1.0$ with $1.011\\pm 0.001$, and for doubles it is $<1.0$ with $0.977\\pm 0.001$.\n",
    "\n",
    "To capture the pile up we need to extend the energy range for the observed-to-model fraction calculations. The default is $500-2000$ eV. Let us set the range to $1000-5000$ eV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec053ac6-8d89-4efc-b8d3-bdf2b4f9be46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inargs = ['set={0}'.format(pn_spectra_file),\n",
    "          'plotfile=pn_epat.ps',\n",
    "          'useplotfile=yes',\n",
    "          'pileupnumberenergyrange=1000 5000',\n",
    "          'withbackgroundset=yes',\n",
    "          'backgroundset={0}'.format(pn_bkg_file)]\n",
    "\n",
    "w('epatplot', inargs).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586c829-737f-405b-a39c-4b8ed20e27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_out = subprocess.run(['gv','pn_epat.ps'],stdout = subprocess.DEVNULL)\n",
    "# Note: You will need to close the window that opens to run the remaining cells in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c08fa5-ee39-4637-99f7-6434c4a9b247",
   "metadata": {},
   "source": [
    "Now the cacluated observed-to-model fractions are $0.988\\pm 0.001$ for singles, and $1.121\\pm 0.001$ for doubles. This shows clear evidence of pile up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e3e42-63c3-4555-8b0d-649635123f51",
   "metadata": {},
   "source": [
    "### 8.7 : My Observation is Piled Up! Now What?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4238f1-a10a-4108-a122-195cba9d61b4",
   "metadata": {},
   "source": [
    "There are a couple ways to deal with pile up. First, you can use event file filtering procedures to include only single pixel events `(PATTERN==0)`, as these events are less sensitive to pile up than other patterns.\n",
    "\n",
    "You can also excise areas of high count rates, i.e., the boresight column and several columns to either side of it. (This is analogous to removing the inner-most regions of a source in Imaging data.) The spectrum can then be re-extracted and you can continue your analysis on the excised event file. As with Imaging data, it is recommended that you take an iterative approach: remove an inner region, extract a spectrum, check with epatplot, and repeat, each time removing a slightly larger region, until the model and observed pattern distributions agree.\n",
    "\n",
    "To extract only the columns to either side of the boresight using the following expression when running `evselect`. All other inputs are the same as in ยง8.5.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> We will not do the additional filtering for pile up here. We will just show the expression and inputs below. If you are only concerned with lower energies in the range of 500-2000 eV then pile up does not significantly affect this observation. But if you are interested in higher energies > 2000 eV, then you will need to correct for pile up. We recommend checking for pile up in the energy range you are interested in by using the <i>pileupnumberenergyrange</i> input for <i>epatplot</i>.\n",
    "</div>\n",
    "\n",
    "```python\n",
    "expression = \"'(FLAG==0)&&(PI in [500:15000])&&(RAWX in [3:5])&&!(RAWX in [29:45])'\"\n",
    "\n",
    "inargs = {}\n",
    "inargs['table']           = basic_filter_file\n",
    "inargs['withspectrumset'] = 'yes'\n",
    "inargs['spectrumset']     = source_pi_file\n",
    "inargs['energycolumn']    = 'PI'\n",
    "inargs['spectralbinsize'] = '5'\n",
    "inargs['withspecranges']  = 'yes'\n",
    "inargs['specchannelmin']  = '0'\n",
    "inargs['specchannelmax']  = '20479'\n",
    "inargs['withfilteredset'] = 'yes'\n",
    "inargs['filteredset']     = pn_spectra_file\n",
    "inargs['expression']      = expression\n",
    "\n",
    "w('evselect', inargs).run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa79ba9-7320-4e52-924f-c8c41b4f7413",
   "metadata": {},
   "source": [
    "### 8.8 : Determine the Spectrum Extraction Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58dfe50-b598-43f7-a1a1-83befac868cb",
   "metadata": {},
   "source": [
    "Now that we are confident that our spectrum is not piled up, we can continue by finding the source and background region areas. (This process is identical to that used for IMAGING data.) This is done with the task backscale, which takes into account any bad pixels or chip gaps, and writes the result into the BACKSCAL keyword of the spectrum table.\n",
    "\n",
    "The inputs are:\n",
    "\n",
    "    -spectrumset - (input) spectrum file\n",
    "    -badpixlocation - (output) event file containing the bad pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff31da-f894-479f-bff0-6ccf0878a79d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inargs = ['spectrumset={0}'.format(source_pi_file),\n",
    "          'badpixlocation=pn_filt.fits']\n",
    "\n",
    "w('backscale', inargs).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb3633-53fc-45e4-bda1-a307394a9186",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inargs = ['spectrumset={0}'.format(bkg_pi_file),\n",
    "          'badpixlocation=pn_filt.fits']\n",
    "\n",
    "w('backscale', inargs).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c4b2e-dad0-451e-b68b-77d52d83042c",
   "metadata": {},
   "source": [
    "### 8.9 : Create the Photon Redistribution Matrix (RMF) and Ancillary File (ARF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46fe46-ef97-47fe-a1a9-ca9b11cff3e8",
   "metadata": {},
   "source": [
    "Making the RMF and ARF for PN data in `TIMING` mode is exactly the same as in `IMAGING` mode, even if you had to excise piled up areas.\n",
    "\n",
    "To make the RMF use `rmfgen`. The inputs are:\n",
    "\n",
    "    -rmfset - output file\n",
    "    -spectrumset - spectrum file\n",
    "\n",
    "rmfgen rmfset=source_rmf_NoBore.fits spectrumset=source_pi_NoBore.fits\n",
    "\n",
    "To make the ARF use `arfgen`. The inputs are:\n",
    "\n",
    "    -arfset - output file\n",
    "    -spectrumset - spectrum file\n",
    "    -arfset - output file\n",
    "    -detmaptype - origin of the detector map\n",
    "    -withrmfset - use the RMF dataset to define the ARF energy grid?\n",
    "    -rmfset - RMF file\n",
    "    -badpixlocation - the file containing the bad pixel locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bafd0f-979f-4534-ab83-7c04f575a43b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inargs = ['rmfset=source_rmf_NoBore.fits',\n",
    "          'spectrumset={0}'.format(source_pi_file)]\n",
    "\n",
    "w('rmfgen', inargs).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88bdae-7a81-4cfd-9a52-2e9789b6ff01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inargs = ['arfset=source_arf_NoBore.fits',\n",
    "          'spectrumset={0}'.format(source_pi_file),\n",
    "          'detmaptype=psf',\n",
    "          'withrmfset=yes',\n",
    "          'rmfset=source_rmf_NoBore.fits',\n",
    "          'badpixlocation=pn_filt.fits']\n",
    "\n",
    "w('arfgen', inargs).run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423e172-9ce6-47af-bf02-8cb9db9d9577",
   "metadata": {},
   "source": [
    "At this point, the spectrum is ready to be analyzed. How to fit the spectrum is explained in [Chapter 13 of the ABC Guide](https://heasarc.gsfc.nasa.gov/docs/xmm/abc/node15.html#Chap:epic-fit-xspec)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
